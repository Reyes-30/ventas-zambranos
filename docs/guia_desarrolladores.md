# üöÄ Gu√≠a para Desarrolladores - Sistema Zambranos

## üéØ Bienvenido al Equipo

Esta gu√≠a te ayudar√° a configurar tu entorno de desarrollo y contribuir efectivamente al Sistema de An√°lisis de Ventas Zambranos. Nuestro objetivo es mantener un c√≥digo de alta calidad, bien documentado y f√°cil de mantener.

---

## üìã Requisitos Previos

### Software Necesario
- **Python 3.9+** (recomendado 3.11)
- **Git** para control de versiones
- **VS Code** (recomendado) con extensiones:
  - Python Extension Pack
  - Pylance (incluido en Python Extension Pack)
  - pytest (para testing)
  - Black Formatter
  - Flake8 (linting)

### Conocimientos Recomendados
- **Python**: Pandas, NumPy, Matplotlib/Plotly
- **Streamlit**: Framework web para aplicaciones de datos
- **Machine Learning**: Scikit-learn b√°sico (PCA, K-Means)
- **Testing**: pytest y conceptos de testing unitario
- **Git**: Flujo de trabajo con branches y pull requests

---

## üõ†Ô∏è Configuraci√≥n del Entorno

### 1. Clonar el Repositorio

```bash
git clone <repository-url>
cd Proyecto
```

### 2. Crear Entorno Virtual

```bash
# Windows
python -m venv venv
venv\Scripts\activate

# macOS/Linux
python -m venv venv
source venv/bin/activate
```

### 3. Instalar Dependencias

```bash
# Dependencias principales
pip install -r requirements.txt

# Dependencias de desarrollo (si existe)
pip install -r requirements-dev.txt

# O instalar dependencias individuales para desarrollo
pip install pytest pytest-benchmark black flake8 mypy
```

### 4. Verificar Instalaci√≥n

```bash
# Ejecutar tests
pytest tests/ -v

# Ejecutar aplicaci√≥n
streamlit run app.py
```

### 5. Configurar Pre-commit Hooks (Opcional pero Recomendado)

```bash
pip install pre-commit
pre-commit install
```

---

## üèóÔ∏è Arquitectura del Proyecto

### Estructura de Directorios

```
Proyecto/
‚îú‚îÄ‚îÄ app.py                      # Aplicaci√≥n principal Streamlit
‚îú‚îÄ‚îÄ requirements.txt            # Dependencias Python
‚îú‚îÄ‚îÄ README.md                   # Documentaci√≥n b√°sica
‚îú‚îÄ‚îÄ 
‚îú‚îÄ‚îÄ src/app/                    # M√≥dulos de l√≥gica de negocio
‚îÇ   ‚îú‚îÄ‚îÄ __init__.py
‚îÇ   ‚îú‚îÄ‚îÄ io_utils.py            # Manejo de archivos y validaci√≥n
‚îÇ   ‚îú‚îÄ‚îÄ processing.py          # An√°lisis y ML
‚îÇ   ‚îú‚îÄ‚îÄ exceptions.py          # Jerarqu√≠a de excepciones
‚îÇ   ‚îî‚îÄ‚îÄ tour_interactivo.py    # Tour guiado de usuario
‚îÇ
‚îú‚îÄ‚îÄ data/                      # Datos del sistema
‚îÇ   ‚îú‚îÄ‚îÄ uploads/              # Archivos subidos por usuarios
‚îÇ   ‚îî‚îÄ‚îÄ outputs/              # Exportaciones generadas
‚îÇ
‚îú‚îÄ‚îÄ tests/                     # Suite de pruebas
‚îÇ   ‚îú‚îÄ‚îÄ test_io_utils.py
‚îÇ   ‚îú‚îÄ‚îÄ test_processing.py
‚îÇ   ‚îú‚îÄ‚îÄ test_ml_algorithms.py
‚îÇ   ‚îú‚îÄ‚îÄ fixtures/             # Datos de prueba
‚îÇ   ‚îî‚îÄ‚îÄ conftest.py           # Configuraci√≥n pytest
‚îÇ
‚îú‚îÄ‚îÄ logs/                      # Archivos de log
‚îÇ   ‚îî‚îÄ‚îÄ app.log
‚îÇ
‚îî‚îÄ‚îÄ docs/                      # Documentaci√≥n
    ‚îú‚îÄ‚îÄ manual_usuario.md
    ‚îú‚îÄ‚îÄ documentacion_tecnica.md
    ‚îî‚îÄ‚îÄ guia_desarrolladores.md
```

### Separaci√≥n de Responsabilidades

#### `app.py` - Capa de Presentaci√≥n
- Interfaz de usuario Streamlit
- Manejo de estado de sesi√≥n
- Coordinaci√≥n entre m√≥dulos
- **NO contiene l√≥gica de negocio**

#### `src/app/io_utils.py` - Capa de Datos
- Lectura y escritura segura de archivos
- Validaci√≥n de esquemas
- Operaciones at√≥micas con locks

#### `src/app/processing.py` - Capa de Negocio
- C√°lculos y an√°lisis de datos
- Algoritmos de Machine Learning
- **Funciones puras sin efectos secundarios**

#### `src/app/exceptions.py` - Manejo de Errores
- Jerarqu√≠a de excepciones personalizada
- Contexto detallado para debugging

#### `src/app/tour_interactivo.py` - Experiencia de Usuario
- Tour guiado paso a paso
- Ayuda contextual por secciones

---

## üé® Est√°ndares de C√≥digo

### Formateo y Style

Usamos **Black** para formateo autom√°tico con configuraci√≥n est√°ndar:

```bash
# Formatear todo el c√≥digo
black src/ tests/ app.py

# Verificar formato sin cambiar
black --check src/ tests/ app.py
```

### Linting

Usamos **Flake8** para an√°lisis de c√≥digo:

```bash
# Verificar todo el c√≥digo
flake8 src/ tests/ app.py

# Configuraci√≥n en setup.cfg (crear si no existe)
[flake8]
max-line-length = 88
extend-ignore = E203, W503
```

### Type Hints

Usamos **type hints** en todas las funciones p√∫blicas:

```python
from typing import Optional, Dict, List, Tuple
import pandas as pd

def procesar_datos(df: pd.DataFrame, columnas: List[str]) -> Dict[str, float]:
    """Funci√≥n con type hints apropiados."""
    pass
```

### Documentaci√≥n

Seguimos el estilo **Google docstrings**:

```python
def ejemplo_funcion(parametro1: str, parametro2: int = 10) -> bool:
    """
    Descripci√≥n breve de la funci√≥n.

    Descripci√≥n m√°s detallada si es necesaria, explicando el contexto
    y uso de la funci√≥n.

    Args:
        parametro1 (str): Descripci√≥n del primer par√°metro
        parametro2 (int, optional): Descripci√≥n del segundo par√°metro. Defaults to 10.

    Returns:
        bool: Descripci√≥n del valor de retorno

    Raises:
        ValueError: Cu√°ndo y por qu√© se lanza esta excepci√≥n
        ProcessingError: Otra excepci√≥n posible

    Examples:
        >>> resultado = ejemplo_funcion("test", 20)
        >>> print(resultado)
        True

    Note:
        Notas adicionales importantes sobre la funci√≥n.
    """
    pass
```

---

## üß™ Testing

### Estructura de Tests

Organizamos tests por m√≥dulo:
- `test_io_utils.py` - Tests de lectura/escritura de archivos
- `test_processing.py` - Tests de l√≥gica de negocio
- `test_ml_algorithms.py` - Tests espec√≠ficos de ML
- `fixtures/` - Datos de prueba reutilizables

### Escribir Tests

#### Test B√°sico
```python
import pytest
import pandas as pd
from src.app.processing import resumen_metricas

def test_resumen_metricas_datos_validos():
    """Test con datos v√°lidos completos."""
    df = pd.DataFrame({
        'Ingreso Total': [1000, 2000, 1500],
        'ISV': [150, 300, 225],
        'Utilidad Bruta': [500, 1000, 750],
        'Cantidad Vendida': [10, 20, 15],
        'Categor√≠a': ['A', 'B', 'A'],
        'Mes': ['Enero', 'Febrero', 'Enero']
    })
    
    resultado = resumen_metricas(df)
    
    assert resultado['total_ingresos'] == 4500
    assert resultado['total_isv'] == 675
    assert resultado['categorias_unicas'] == 2
    assert resultado['meses_activos'] == 2
```

#### Test con Excepciones
```python
def test_validacion_columnas_faltantes():
    """Test que verifica manejo de columnas faltantes."""
    df_incompleto = pd.DataFrame({'Mes': ['Enero']})
    
    with pytest.raises(ValidationError) as exc_info:
        validate_schema(df_incompleto)
    
    assert "Faltan columnas requeridas" in str(exc_info.value)
```

#### Fixtures para Datos de Prueba
```python
@pytest.fixture
def sample_dataframe():
    """Fixture con DataFrame de ejemplo para tests."""
    return pd.DataFrame({
        'Mes': ['Enero', 'Febrero', 'Marzo'],
        'Categor√≠a': ['A', 'B', 'A'],
        'Cantidad Vendida': [100, 200, 150],
        'Ingreso Total': [1000, 2000, 1500],
        'ISV': [150, 300, 225],
        'Utilidad Bruta': [500, 1000, 750]
    })

def test_con_fixture(sample_dataframe):
    """Test usando fixture de datos."""
    resultado = resumen_metricas(sample_dataframe)
    assert isinstance(resultado, dict)
```

### Ejecutar Tests

```bash
# Todos los tests
pytest

# Tests con verbose output
pytest -v

# Tests espec√≠ficos
pytest tests/test_processing.py

# Tests con coverage
pytest --cov=src/app --cov-report=html

# Solo tests r√°pidos (excluir benchmarks)
pytest --benchmark-skip

# Solo benchmarks de performance
pytest --benchmark-only
```

---

## üîÑ Flujo de Desarrollo

### Workflow de Git

1. **Crear rama feature**
```bash
git checkout -b feature/nueva-funcionalidad
```

2. **Desarrollar y hacer commits**
```bash
git add .
git commit -m "feat: agregar nueva funcionalidad de an√°lisis"
```

3. **Ejecutar tests localmente**
```bash
pytest tests/ -v
black --check src/ tests/ app.py
flake8 src/ tests/ app.py
```

4. **Push y crear Pull Request**
```bash
git push origin feature/nueva-funcionalidad
# Crear PR en GitHub/GitLab
```

### Convenciones de Commits

Usamos **Conventional Commits**:

```bash
feat: nueva funcionalidad
fix: correcci√≥n de bug
docs: actualizaci√≥n de documentaci√≥n
style: cambios de formato (no afectan l√≥gica)
refactor: refactoring de c√≥digo
test: agregar o modificar tests
chore: tareas de mantenimiento
```

Ejemplos:
```bash
git commit -m "feat: agregar algoritmo de clustering jer√°rquico"
git commit -m "fix: corregir validaci√≥n de archivos Excel"
git commit -m "docs: actualizar documentaci√≥n de API"
git commit -m "test: agregar tests para funciones de ML"
```

---

## üÜï Agregar Nuevas Funcionalidades

### 1. Nuevo An√°lisis de Datos

#### Paso 1: Definir Resultado
```python
# En src/app/processing.py
@dataclass
class NuevoAnalisisResult:
    """Resultado del nuevo an√°lisis."""
    metric_principal: float
    detalles: Dict[str, any]
    interpretacion: str
```

#### Paso 2: Implementar Funci√≥n
```python
def nuevo_analisis(df: pd.DataFrame, parametros: Dict) -> NuevoAnalisisResult:
    """
    Implementa nuevo tipo de an√°lisis.

    Args:
        df: DataFrame con datos validados
        parametros: Configuraci√≥n del an√°lisis

    Returns:
        NuevoAnalisisResult: Resultado estructurado

    Raises:
        ProcessingError: Si hay problemas en el c√°lculo
    """
    try:
        # L√≥gica del an√°lisis aqu√≠
        resultado = calcular_nueva_metrica(df, parametros)
        
        return NuevoAnalisisResult(
            metric_principal=resultado,
            detalles=crear_detalles(df),
            interpretacion=generar_interpretacion(resultado)
        )
    except Exception as e:
        raise ProcessingError("Error en nuevo an√°lisis", detail=str(e))
```

#### Paso 3: Escribir Tests
```python
# En tests/test_processing.py
def test_nuevo_analisis_datos_validos():
    """Test del nuevo an√°lisis con datos v√°lidos."""
    df = crear_dataframe_ejemplo()
    parametros = {'param1': 'valor1'}
    
    resultado = nuevo_analisis(df, parametros)
    
    assert isinstance(resultado, NuevoAnalisisResult)
    assert resultado.metric_principal > 0
    assert 'interpretacion' in resultado.interpretacion
```

#### Paso 4: Integrar en UI
```python
# En app.py, agregar nueva tab o secci√≥n
with tab_nuevo_analisis:
    st.header("üîç Nuevo An√°lisis")
    
    # Controles de configuraci√≥n
    param1 = st.selectbox("Par√°metro 1", opciones)
    
    if st.button("Ejecutar An√°lisis"):
        try:
            resultado = nuevo_analisis(st.session_state.df, {'param1': param1})
            
            # Mostrar resultados
            st.metric("M√©trica Principal", f"{resultado.metric_principal:.2f}")
            st.write(resultado.interpretacion)
            
        except ProcessingError as e:
            st.error(f"Error en an√°lisis: {e}")
```

### 2. Nueva Visualizaci√≥n

#### Crear Funci√≥n de Plot
```python
def crear_nueva_visualizacion(df: pd.DataFrame, **kwargs) -> Figure:
    """
    Crea nueva visualizaci√≥n personalizada.

    Args:
        df: DataFrame con datos
        **kwargs: Par√°metros de configuraci√≥n

    Returns:
        Figure: Figura de Plotly o Matplotlib
    """
    if kwargs.get('interactivo', True):
        # Versi√≥n Plotly
        fig = px.scatter(df, x='x_col', y='y_col', **kwargs)
        fig.update_layout(template="plotly_white")
        return fig
    else:
        # Versi√≥n Matplotlib
        fig, ax = plt.subplots(figsize=(10, 6))
        ax.scatter(df['x_col'], df['y_col'])
        return fig
```

#### Integrar con Sistema de Exportaci√≥n
```python
# En app.py
fig = crear_nueva_visualizacion(df, interactivo=mostrar_interactivas)

if isinstance(fig, go.Figure):
    st.plotly_chart(fig, use_container_width=True)
    _record_plotly(fig, "nueva_visualizacion")
else:
    st.pyplot(fig)
    _record_matplotlib(fig, "nueva_visualizacion")
```

---

## üîß Debugging y Troubleshooting

### Logging para Development

```python
import logging

# Configurar logging m√°s detallado para desarrollo
logging.basicConfig(
    level=logging.DEBUG,
    format='%(asctime)s - %(name)s - %(levelname)s - %(filename)s:%(lineno)d - %(message)s'
)

logger = logging.getLogger(__name__)

def mi_funcion(datos):
    logger.debug(f"Procesando {len(datos)} registros")
    
    try:
        resultado = procesar(datos)
        logger.info(f"Procesamiento exitoso: {resultado}")
        return resultado
    except Exception as e:
        logger.error(f"Error procesando datos: {e}", exc_info=True)
        raise
```

### Debugging en Streamlit

```python
# Usar st.write para debugging r√°pido
st.write("DEBUG: Valor de variable", variable)

# Mostrar estructura de DataFrame
st.write("DEBUG: DataFrame info")
st.dataframe(df.head())
st.write(f"Shape: {df.shape}, Columns: {df.columns.tolist()}")

# Mostrar estado de sesi√≥n
if st.checkbox("Mostrar session_state"):
    st.write(st.session_state)
```

### Problemas Comunes

#### Error: "ModuleNotFoundError"
```bash
# Verificar que est√°s en el entorno virtual correcto
which python
pip list

# Reinstalar dependencias
pip install -r requirements.txt
```

#### Error: "Streamlit command not found"
```bash
# Instalar Streamlit en el entorno virtual
pip install streamlit

# Verificar instalaci√≥n
streamlit --version
```

#### Error: Tests Fallan
```bash
# Ejecutar test espec√≠fico con m√°s detalle
pytest tests/test_especifico.py::test_funcion -v -s

# Verificar que todos los m√≥dulos se pueden importar
python -c "from src.app import io_utils, processing, exceptions"
```

---

## üìö Recursos y Referencias

### Documentaci√≥n Oficial
- [Streamlit Docs](https://docs.streamlit.io/)
- [Pandas User Guide](https://pandas.pydata.org/docs/user_guide/)
- [Plotly Python](https://plotly.com/python/)
- [Scikit-learn](https://scikit-learn.org/stable/user_guide.html)
- [pytest Documentation](https://docs.pytest.org/)

### Herramientas de Desarrollo
- [Black Code Formatter](https://black.readthedocs.io/)
- [Flake8 Linter](https://flake8.pycqa.org/)
- [MyPy Type Checker](https://mypy.readthedocs.io/)
- [Pre-commit Hooks](https://pre-commit.com/)

### Estilo y Convenciones
- [PEP 8 - Style Guide](https://www.python.org/dev/peps/pep-0008/)
- [Google Python Style Guide](https://google.github.io/styleguide/pyguide.html)
- [Conventional Commits](https://www.conventionalcommits.org/)

---

## ü§ù Proceso de Contribuci√≥n

### Checklist antes de Pull Request

- [ ] **C√≥digo formateado** con Black
- [ ] **Linting limpio** con Flake8
- [ ] **Tests escritos** para nueva funcionalidad
- [ ] **Tests pasando** localmente
- [ ] **Documentaci√≥n actualizada** (docstrings, README, etc.)
- [ ] **Commits descriptivos** siguiendo convenciones
- [ ] **Sin archivos sensibles** (logs, datos privados, etc.)

### Code Review

Cuando hagas review de c√≥digo, considera:

#### Funcionalidad
- ¬øEl c√≥digo hace lo que se supone?
- ¬øManeja casos edge apropiadamente?
- ¬øTiene validaci√≥n de entrada adecuada?

#### Mantenibilidad
- ¬øEs f√°cil de entender?
- ¬øEst√° bien documentado?
- ¬øSigue los patrones establecidos?

#### Performance
- ¬øEs eficiente para datasets grandes?
- ¬øPodr√≠a causar memory leaks?
- ¬øUsa las mejores pr√°cticas de pandas/numpy?

#### Testing
- ¬øTiene cobertura de tests adecuada?
- ¬øLos tests son claros y completos?
- ¬øIncluye tests de casos edge?

---

## üöÄ Deployment

### Para Desarrollo Local
```bash
streamlit run app.py --server.headless false
```

### Para Producci√≥n con Docker
```dockerfile
FROM python:3.11-slim

WORKDIR /app
COPY requirements.txt .
RUN pip install -r requirements.txt

COPY . .
RUN mkdir -p data/uploads logs

EXPOSE 8501
CMD ["streamlit", "run", "app.py", "--server.address", "0.0.0.0"]
```

### Variables de Entorno
```bash
# .env file para configuraci√≥n
STREAMLIT_SERVER_HEADLESS=true
STREAMLIT_SERVER_ENABLE_CORS=false
STREAMLIT_THEME_PRIMARY_COLOR="#1e3c72"
LOG_LEVEL=INFO
```

---

## üìû Soporte y Contacto

### Para Problemas T√©cnicos
1. Revisar logs en `logs/app.log`
2. Verificar issues conocidos en documentaci√≥n
3. Ejecutar suite de tests para verificar integridad
4. Contactar al equipo senior si persiste el problema

### Para Nuevas Ideas
1. Crear issue en el repositorio
2. Discutir en reuniones de equipo
3. Crear documento de dise√±o para features grandes
4. Implementar MVP para validar concepto

---

*¬°Bienvenido al equipo! Esta gu√≠a es un documento vivo que mejora con la experiencia del equipo.*

*√öltima actualizaci√≥n: Septiembre 2025*  
*Versi√≥n: 2.0*
